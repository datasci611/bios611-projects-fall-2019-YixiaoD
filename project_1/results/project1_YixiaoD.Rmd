---
title: "project1_YixiaoD"
output: html_document
---
# Background
UMD(Urban Ministries of Durham) is a non-profit orgnization which connects with the community to end homelessness and fight poverty by offering food, shelter and a future to neighbors in need. This project is designed to dig into the data provided by UMD and find something valuable for the staff who are working for the orgnization.  
In this project, I want to predict whether a person comes for help will come back again based on the aid he gets this time, the times of he came before and the average aid he got before. 

# Data
The data source is provided by UMD and the raw data file is given in the data dictionary.

# What I am interesting about
I summarise the coming times of different clients and show it with bar plot.
```{r include = FALSE}
library(tidyverse)

#read dataset
raw_df <- read_tsv("/Users/Yixiao/Desktop/611project/project_1/data/UMD_Services_Provided_20190719.tsv")
```
```{r}
come_times <- raw_df %>%
  group_by(`Client File Number`) %>%
  summarise(coming_times = n()) %>%
  filter(coming_times <= 30)
ggplot(come_times) +
  geom_bar(aes(coming_times)) 
```

The figure shows that most clients only come once. So I wonder if we could predict whether a client will come again, we can pay more attention to those who is likely to come again since thay may need more help than those who will not come again.

# Goal of the project
In this project, I try to predict whether a client will visit again when he comes for help. From the data provided by UMD, for each record we can get the following information: the date, what help the client get, whether the client come again after this visit and the similiar information about his previous visits if this is not his first visit. 

# Design of the project
First, we need to do data cleasing and transformation to get a data frame which is appropriate for machine learning model. Then we split the data into train set and test set, train the model using the machine learning method, predict on the test set and evaluate the accuracy of prediction. In the end, we try to improve the accuracy of prediction by trying other models or methods.

# Data Cleasing
The raw data is hard to analyse. Therefore, data cleansing is condected.
Firstly, I notice that some records are so old while some happen in the future. So I plot how many record are there in each year.
```{r}
#separate Date and change type
df <- separate(raw_df, Date, into = c("month", "day", "year"), sep = "/")
df$month <- as.numeric(df$month)
df$day <- as.numeric(df$day)
df$year <- as.numeric(df$year)

#count how many people com for help each year
count_year <- df %>% group_by(year) %>% summarise(count = n())
ggplot(count_year) +
  geom_point(aes(year, count))
```

From the figure we can see that there are little records before 2001. This is consistent with the history of UMD: In 2001, the Durham Community Shelter for HOPE, St. Philipâ€™s Community Cafe, and the United Methodist Mission Society merged to form Urban Ministries of Durham (From UMD website). Also, there are some records happening in the future.
Therefore, we delete the records in the years before 2001 and those records which happen in the future (after Sep 2019).
```{r}
df <- df %>%
  filter(year >= 2001 & year <= 2019) %>%
  filter(year < 2019 | (year == 2019 & month <=9))
```

Since some columns are useless, we only keep the columns about date, client number, food, cloth, diaper, school kit and dyiene kit (the bus tickets and money providing service are discontinued so I removed them as well).
```{r}
df <- df %>%
  select( month : `Hygiene Kits`) %>%
  select(-`Bus Tickets (Number of)`, -`Notes of Service`)
df[is.na(df)] <- 0
```

What is more, I merge the "Client File Number" and "Client File Merge" into one columns. In this way, different members in a family who come for help will be considered as one client. To achieve this, I use loop statement. For each record, if the Client File Merge is not 0, the replace the Client File Number with Client File Merge. Moreover, I add an column to record the household type of the client.
```{r}
# merge Client file Number
df <- add_column(df, `Household Type` = 0)
for (i in 1:nrow(df)) {
  if (df[i,"Client File Merge"] != 0) {
    df[i,"Client File Number"] = df[i,"Client File Merge"]
    df[i,"Household Type"] = 1
  }
}
df <- select(df, -`Client File Merge`)
```

Up to now, the data cleasing is completed.

# Data Transformation
Since we want to predict whether a client will come again or not, for each record in the data, we need to add a variable showing that whether the client come again after this visit.
```{r}
#Come Again: 0 means not visit again, 1 means visit again
df <- arrange(df, `Client File Number`, year, month, day)
df <- add_column(df, `Come Again` = 0)
for (i in 1:(nrow(df)-1)) {
  if (df[i+1,"Client File Number"] == df[i,"Client File Number"]) {df[i,"Come Again"] = 1}
}
```
For each record, we can also get the following information based on the existing data:
* the household type of the client: single or family
* how many times the client visits before
* the average quantity of aid the client gets before
* the days number between this visit and last visit
```{r}
df <- add_column(df,`Come Number Before` = 0, 
                 `Days Since Last Visit` = 0,
                 `Avg Food Provided For Before` = 0, 
                 `Avg Food Pounds Before` = 0,
                 `Avg Clothing Items Before` = 0,
                 `Avg Diapers Before` = 0,
                 `Avg School Kits Before` = 0,
                 `Avg Hygiene Kits Before` = 0,)
k<-1
for (i in 2:nrow(df)) {
  if (df[i-1,"Client File Number"] == df[i,"Client File Number"]) {
    df[i,"Come Number Before"] = i-k
    df[i,"Days Since Last Visit"] = df[i,"day"] - df[i-1,"day"] + 30 * (df[i,"month"] - df[i-1,"month"]) + 365 * (df[i,"year"] - df[i-1,"year"])
    for (j in 15:ncol(df)) {
      df[i,j] = sum(df[k:(i-1),(j-10)]) / (i-k)
    }
  }
  else {k = i}
}
```

# Classification: xgboost
```{r}
library(tidyverse)
require(xgboost)

dataset <- read.csv("/Users/Yixiao/Desktop/611project/project_1/data/dataset.csv")
dataset$Come.Again <- as.factor(dataset$Come.Again)

data_ind <- sample(seq_len(nrow(dataset)), size = 10000)
data <- dataset[data_ind,]

#Randomly split the data set into 2 halves
smp_size <- floor(0.8 * nrow(data))
set.seed(0)
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <- data[train_ind,] 
test <- data[-train_ind,] 
train_label <- select(train, Come.Again) %>% as.matrix()
test_label <- select(test, Come.Again) %>% as.matrix()
train_feature <- select(train, -Come.Again, -year, -month, -day, -Client.File.Number) %>% as.matrix()
test_feature <- select(test, -Come.Again, -year, -month, -day,-Client.File.Number) %>% as.matrix()
#xgboost
xgb <- xgboost(data = train_feature, 
               label = train_label, 
               max_depth = 5, 
               nround=100, 
               subsample = 0.5,
               colsample_bytree = 0.5,
               eval_metric = "auc",
               objective = "binary:logistic",
               silent = 1
)

test_prob <- predict(xgb, test_feature)
test_pred <- test_prob >0.5

tp = sum(test_label==1&test_pred==1)
precision = tp/sum(test_pred)
print(paste("tp=",tp))
print(paste("precision=",precision))
```




