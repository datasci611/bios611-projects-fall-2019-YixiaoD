2*sum(dbinom(0:1,6,0.5)
sdkf
2*sum(dbinom(0:1,6,0.5))
2*sum(dbinom(0,6,0.5))
2*sum(dbinom(0,5,0.5))
pbinom(0,5,0.5)
2*sum(dbinom(0:1,5,0.5))
library("BSDA")
SIGN.test(diff)
pre <- c(110, 101, 61, 73, 143, 118)
post <- c(149, 105, 162, 93, 143, 100)
diff <- post - pre
t.test(diff, alternative = "two.sided")
case
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
case
View(case)
View(case)
data <- select(data, month, day, year, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds, Clothing.Items)
View(data)
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
View(data_sel)
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
View(data_sel)
group_by(data, year, month)
summarise(total_food = sum(Food.Pounds))
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
#
data_sel <- data %>%
select( month, day, year, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds, Clothing.Items) %>%
filter(year >= 1999 & year <= 2019) %>%
filter(is.na(Food.Pounds) == FALSE & is.na(Clothing.Items) == FALSE)
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
View(data)
View(data)
View(data)
View(data)
group_by(data, year, month)
summarise(data, total_food = sum(Food.Pounds), na.rm = TRUE)
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
source('~/Desktop/611project/project_1/scripts/project 1 .R', echo=TRUE)
data_year <- group_by(data, year) %>% summarise(count = n())
data_year
data_food <- group_by(data, year, month) %>% summarise(food = sum(Food.Pounds))
data_food
View(data_food)
View(data_food)
data_food <- group_by(data, year, month) %>% summarise(food = sum(Food.Pounds), na.rm = TRUE)
View(data_food)
View(data_food)
#
data_sel <- data %>%
select( month, day, year, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds, Clothing.Items) %>%
filter(year >= 1999 & year <= 2019) %>%
filter(is.na(Food.Pounds) == FALSE & is.na(Clothing.Items) == FALSE)
data_food <- group_by(data_sel, year, month) %>% summarise(food = sum(Food.Pounds), na.rm = TRUE)
View(data_food)
View(data_food)
View(data_food)
View(data_food)
View(data_sel)
View(data_sel)
#
data_sel <- data %>%
select( month, day, year, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds, Clothing.Items) %>%
filter(year >= 1999 & year <= 2019) %>%
filter(is.na(Food.Pounds) == FALSE & is.na(Clothing.Items) == FALSE)
food_month <- group_by(data_sel, year, month) %>% summarise(food = sum(Food.Pounds), na.rm = TRUE)
cloth_month <- group_by(data_sel, year, month) %>% summarise(cloth = sum(Clothing.Items), na.rm = TRUE)
View(cloth_month)
View(cloth_month)
CI_lower <- mean(diff) - qt(0.995, 5) * sd(diff) / sqrt(6)
CI_upper <- mean(diff) + qt(0.995, 5) * sd(diff) / sqrt(6)
print(paste("99% confidence interval on the difference is:","[",CI_lower,",",CI_upper,"]"))
wilcox.test(pre, post, alternative = "two.sided", exact = F, correct = F)
wilcox.exact(pre, post, alternative = "two.sided")
wilcox.exact(pre, post)
wilcox.exact(pre, post)
install.packages("exactRankTests")
wilcox.exact(pre, post)
library(exactRankTests)
library(exactRankTests)
wilcox.exact(pre, post)
wilcox.test(pre, post, exact = F, correct = F)
men_CHD <- filter(data, CHD ==1 & gender == "M")
library(exactRankTests)
men_CHD <- filter(data, CHD ==1 & gender == "M")
library(tidyverse)
data <- read.delim("/Users/Yixiao/Desktop/class/662/homework/CH3_CHOL.txt", header = TRUE, sep = "")
CHD <- filter(data, CHD == 1)
CHD_not <- filter(data, CHD ==0)
t.test(CHD$total_cholesterol_value, CHD_not$total_cholesterol_value,
var.equal = TRUE, alternative = "two.sided")
men_CHD <- filter(data, CHD ==1 & gender == "M")
men_CHD_not <- filter(data, CHD ==0 & gender == "M")
wilcox.exact(men_CHD$total_cholesterol_value,men_CHD_not$total_cholesterol_valueï¼‰
men_CHD <- filter(data, CHD ==1 & gender == "M")
men_CHD_not <- filter(data, CHD ==0 & gender == "M")
wilcox.exact(men_CHD$total_cholesterol_value,men_CHD_not$total_cholesterol_value)
library(exactRankTests)
library(exactRankTests)
men_CHD <- filter(data, CHD ==1 & gender == "M")
men_CHD_not <- filter(data, CHD ==0 & gender == "M")
wilcox.exact(men_CHD$total_cholesterol_value,men_CHD_not$total_cholesterol_value)
install.packages("caret")
source('~/Desktop/class/611/classify_example.R', echo=TRUE)
library(tidyverse)
library(mclust)
# A quick refresher on native R clustering algorithms: https://www.statmethods.net/advstats/cluster.html
# Set the random seed
set.seed(0)
# Generate example data set
N = 30
U1 = 1
U2 = 4.5
gene_df = rbind(tibble(gene_a = rnorm(n=N, mean=U2), gene_b = rnorm(n=N, mean=U1), explant_id = seq(1, N), type = 1),
tibble(gene_a = rnorm(n=N, mean=U1), gene_b = rnorm(n=N, mean=U1), explant_id = seq(N+1, 2*N), type = 2),
tibble(gene_a = rnorm(n=N, mean=U1), gene_b = rnorm(n=N, mean=U2), explant_id = seq((2*N)+1, 3*N), type = 3))
gene_df$type = as.factor(gene_df$type)
View(gene_df)
View(gene_df)
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75)
library(caret)
# Expected to be from type 2
new_samples = tibble(gene_a = rnorm(n=10, mean=2), gene_b = rnorm(n=10, mean=2))
# Train a k-nearest-neighbors model
knn_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "knn")
# Predict type for new data
knn_classification = predict(knn_fit, new_samples, type="raw")
new_samples$knn_class = knn_classification
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=new_samples, size=4, aes(color=new_samples$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
View(new_samples)
# Train a support vector machine
svm_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "svmLinear")
# Train a support vector machine
svm_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "svmLinear")
# Train a random forest classifier
rf_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "ranger")
library(caret)
# Train a k-nearest-neighbors model
knn_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "knn")
# Predict type for new data
knn_classification = predict(knn_fit, new_samples, type="raw")
new_samples$knn_class = knn_classification
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=new_samples, size=4, aes(color=new_samples$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
View(new_samples)
View(new_samples)
# Train a support vector machine
svm_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "svmLinear")
# Predict type for new data
svm_classification = predict(svm_fit, new_samples, type="raw")
new_samples$svm_class = svm_classification
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=new_samples, size=4, aes(color=new_samples$svm_class)) +
ggtitle('svm_classification') +
theme(legend.position = "none")
View(new_samples)
View(new_samples)
# Train a random forest classifier
rf_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "ranger")
# Predict type for new data
rf_classification = predict(rf_fit, new_samples, type="raw")
new_samples$rf_class = rf_classification
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=new_samples, size=4, aes(color=new_samples$rf_class)) +
ggtitle('rf_classification') +
theme(legend.position = "none")
View(new_samples)
View(new_samples)
library(tidyverse)
#read data
raw_data <- read.delim("/Users/Yixiao/Desktop/611project/project_1/data/UMD_Services_Provided_20190719.tsv",sep = "\t")
data <- select(raw_data, Date, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds,
Clothing.Items, Diapers, School.Kits, Hygiene.Kits)
# number of different kinds of aid
food <- count(filter(data, is.na(Food.Pounds) == FALSE))
cloth <- count(filter(data, is.na(Clothing.Items) == FALSE))
diaper <- count(filter(data, is.na(Diapers) == FALSE))
school_kit <- count(filter(data, is.na(School.Kits) == FALSE))
hygiene_kit <- count(filter(data, is.na(Hygiene.Kits) == FALSE))
case <- tibble(type = c("food", "cloth", "diaper", "school_kit", "hygiene_kit"), n = c(food, cloth, diaper, school_kit, hygiene_kit))
ggplot(case, aes(type, n))+
geom(bar)
library(tidyverse)
#read data
raw_data <- read.delim("/Users/Yixiao/Desktop/611project/project_1/data/UMD_Services_Provided_20190719.tsv",sep = "\t")
data <- select(raw_data, Date, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds,
Clothing.Items, Diapers, School.Kits, Hygiene.Kits)
# number of different kinds of aid
food <- count(filter(data, is.na(Food.Pounds) == FALSE))
cloth <- count(filter(data, is.na(Clothing.Items) == FALSE))
diaper <- count(filter(data, is.na(Diapers) == FALSE))
school_kit <- count(filter(data, is.na(School.Kits) == FALSE))
hygiene_kit <- count(filter(data, is.na(Hygiene.Kits) == FALSE))
case <- tibble(type = c("food", "cloth", "diaper", "school_kit", "hygiene_kit"), n = c(food, cloth, diaper, school_kit, hygiene_kit))
ggplot(case, aes(type, n))+
geom_bar()
ggplot(data, aes(case$type))+
geom_bar()
aid_kind <- c("Food.Provided.for", "Food.Pounds",
"Clothing.Items", "Diapers", "School.Kits", "Hygiene.Kits")
ggplot(data, aes(aid_kind))+
geom_bar()
aid_kind <- c("Food.Provided.for", "Food.Pounds",
"Clothing.Items", "Diapers", "School.Kits", "Hygiene.Kits")
ggplot(data, aes(aid_kind))+
geom_bar(na.rm = TRUE)
case <- tibble(type = c("food", "cloth", "diaper", "school_kit", "hygiene_kit"), n = c(food, cloth, diaper, school_kit, hygiene_kit))
aid_kind <- c("Food.Provided.for", "Food.Pounds",
"Clothing.Items", "Diapers", "School.Kits", "Hygiene.Kits")
ggplot(case, aes(type,n))+
geom_point()
ggplot(case, aes(case$type,case$n))+
geom_point()
case
View(data_year)
View(data_year)
ggplot(data_year, aes(year,count))+
geom_point()
data_year <- group_by(data, year) %>% summarise(count = n()) %>% filter(count > 100)
ggplot(data_year, aes(year,count))+
geom_point()
library(tidyverse)
#read data
raw_data <- read.delim("/Users/Yixiao/Desktop/611project/project_1/data/UMD_Services_Provided_20190719.tsv",sep = "\t")
#data selection: Data, client, food, cloth, diaper, school kit, hygiene kit
data <- select(raw_data, Date, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds,
Clothing.Items, Diapers, School.Kits, Hygiene.Kits)
#separate Date, change type and sort according to date
data <- separate(data, Date, into = c("month", "day", "year"), sep = "/")
data$month <- as.numeric(data$month)
data$day <- as.numeric(data$day)
data$year <- as.numeric(data$year)
data <- arrange(data, year, month, day)
data_year <- group_by(data, year) %>% summarise(count = n()) %>% filter(count > 100)
ggplot(data_year, aes(year,count))+
geom_point()
library(tidyverse)
#read data
raw_data <- read.delim("/Users/Yixiao/Desktop/611project/project_1/data/UMD_Services_Provided_20190719.tsv",sep = "\t")
#data selection: Data, client, food, cloth, diaper, school kit, hygiene kit
data <- select(raw_data, Date, Client.File.Number, Client.File.Merge, Food.Provided.for, Food.Pounds,
Clothing.Items, Diapers, School.Kits, Hygiene.Kits)
#separate Date, change type and sort according to date
data <- separate(data, Date, into = c("month", "day", "year"), sep = "/")
data$month <- as.numeric(data$month)
data$day <- as.numeric(data$day)
data$year <- as.numeric(data$year)
data <- arrange(data, year, month, day)
data_year <- group_by(data, year) %>% summarise(count = n()) %>% filter(count > 100)
ggplot(data_year, aes(year,count))+
geom_point()
data_year <- group_by(data, year) %>% summarise(count = n()) %>% filter(count > 100)
data_sel <- filter(data, year >= 2002 & year <= 1999)
data_month <- group_by(data, year, month) %>% summarise(count = n())
View(data_month)
View(data_month)
data_sel <- filter(data, year >= 2002 & year <= 1999)
data_month <- group_by(data, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, year = year))+
geom_line()
data_sel <- filter(data, year >= 2002 & year <= 1999)
data_month <- group_by(data, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, color = year))+
geom_line()
View(data_month)
data_sel <- filter(data, year >= 2002 & year <= 1999)
data_month <- group_by(data_sel, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, color = year))+
geom_line()
View(data_month)
View(data_month)
View(data_sel)
View(data_sel)
data_sel <- filter(data, year >= 2002 & year <= 2019)
data_month <- group_by(data_sel, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, color = year))+
geom_line()
data_year <- group_by(data, year) %>% summarise(count = n()) %>% filter(count > 100)
ggplot(data_year, aes(year,count))+
geom_point()
data_sel <- filter(data, year >= 2002 & year <= 2019)
data_month <- group_by(data_sel, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, type = year))+
geom_line()
View(data_month)
View(data_month)
data_month <- group_by(data_sel, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, color = year))+
geom_line()
data_sel <- filter(data, year >= 2002 & year <= 2019)
data_month <- group_by(data_sel, year, month) %>% summarise(count = n())
ggplot(data_month, aes(month, count, color = year))+
geom_point()
gplot(data_year, aes(year,count))+
geom_point()
ggplot(data_year, aes(year,count))+
geom_point()
data_year <- group_by(data, year) %>% summarise(count = n()) %>% filter(year >= 1990)
ggplot(data_year, aes(year,count))+
geom_point()
data <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv")
View(data)
View(data)
View(df)
View(df)
library(tidyverse)
library(mclust)
# A quick refresher on native R clustering algorithms: https://www.statmethods.net/advstats/cluster.html
# Set the random seed
set.seed(0)
# Generate example data set
N = 30
U1 = 1
U2 = 4.5
gene_df = rbind(tibble(gene_a = rnorm(n=N, mean=U2), gene_b = rnorm(n=N, mean=U1), explant_id = seq(1, N), type = 1),
tibble(gene_a = rnorm(n=N, mean=U1), gene_b = rnorm(n=N, mean=U1), explant_id = seq(N+1, 2*N), type = 2),
tibble(gene_a = rnorm(n=N, mean=U1), gene_b = rnorm(n=N, mean=U2), explant_id = seq((2*N)+1, 3*N), type = 3))
gene_df$type = as.factor(gene_df$type)
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75)
# Train a k-nearest-neighbors model
knn_fit = train(type ~ gene_a + gene_b, data = gene_df, method = "knn")
# Predict type for new data
knn_classification = predict(knn_fit, new_samples, type="raw")
new_samples$knn_class = knn_classification
ggplot(gene_df, aes(gene_a, gene_b)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=new_samples, size=4, aes(color=new_samples$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
knn_fit
knn_classification
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind]
test <- df[-train_ind]
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind]
test <- df[-train_ind]
source('~/.active-rstudio-document', echo=TRUE)
train
View(train)
View(train)
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind,]
test <- df[-train_ind,]
#Cluster the cities into 3 groups using K-means
fit = train %>%
select(all, white, non.white) %>%
kmeans(3)
df$cluster = as.factor(fit$cluster)
#k-nearest neighbours
knn_fit = train(cluster ~ all + white + non-white, data = train, method = "knn")
knn_classification = predict(knn_fit, test, type="raw")
test$knn_class = knn_classification
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind,]
test <- df[-train_ind,]
#Cluster the cities into 3 groups using K-means
fit = train %>%
select(all, white, non.white) %>%
kmeans(3)
df$cluster = as.factor(fit$cluster)
#k-nearest neighbours
knn_fit = train(cluster ~ all + white + non.white, data = train, method = "knn")
knn_classification = predict(knn_fit, test, type="raw")
test$knn_class = knn_classification
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind,]
test <- df[-train_ind,]
#Cluster the cities into 3 groups using K-means
fit = df %>%
select(all, white, non.white) %>%
kmeans(3)
train$cluster = as.factor(fit$cluster)
#k-nearest neighbours
knn_fit = train(cluster ~ all + white + non.white, data = train, method = "knn")
knn_classification = predict(knn_fit, test, type="raw")
test$knn_class = knn_classification
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind,]
test <- df[-train_ind,]
#Cluster the cities into 3 groups using K-means
fit = train %>%
select(all, white, non.white) %>%
kmeans(3)
train$cluster = as.factor(fit$cluster)
#k-nearest neighbours
knn_fit = train(cluster ~ all + white + non.white, data = train, method = "knn")
knn_classification = predict(knn_fit, test, type="raw")
test$knn_class = knn_classification
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind,]
test <- df[-train_ind,]
#Cluster the cities into 3 groups using K-means
fit = train %>%
select(all, white, non.white) %>%
kmeans(3)
train$cluster = as.factor(fit$cluster)
#k-nearest neighbours
knn_fit = train(cluster ~ all + white + non.white, data = train, method = "knn")
knn_classification = predict(knn_fit, test, type="raw")
test$knn_class = knn_classification
ggplot(train, aes(white, non-white)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
library(tidyverse)
df <- read.csv("/Users/Yixiao/Desktop/611homework/class_examples/police-locals.csv", na = '**')
#Randomly split the data set into 2 halves
smp_size <- floor(0.5 * nrow(df))
set.seed(0)
train_ind <- sample(seq_len(nrow(df)), size = smp_size)
train <- df[train_ind,]
test <- df[-train_ind,]
#Cluster the cities into 3 groups using K-means
fit = train %>%
select(all, white, non.white) %>%
kmeans(3)
train$cluster = as.factor(fit$cluster)
#k-nearest neighbours
knn_fit = train(cluster ~ all + white + non.white, data = train, method = "knn")
knn_classification = predict(knn_fit, test, type="raw")
test$knn_class = knn_classification
ggplot(train, aes(white, non.white)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
#SVM
svm_fit = train(cluster ~ all + white + non.white, data = train, method = "svmLinear")
svm_classification = predict(svm_fit, test, type="raw")
test$svm_class = svm_classification
ggplot(train, aes(white, non.white)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$svm_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
#SVM
svm_fit = train(cluster ~ all + white + non.white, data = train, method = "svmLinear")
svm_classification = predict(svm_fit, test, type="raw")
test$svm_class = svm_classification
ggplot(train, aes(white, non.white)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$svm_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
ggplot(train, aes(white, non.white)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$knn_class)) +
ggtitle('knn_classification') +
theme(legend.position = "none")
#random forest
rf_fit = train(cluster ~ all + white + non.white, data = train, method = "ranger")
rf_classification = predict(rf_fit, test, type="raw")
test$rf_class = rf_classification
ggplot(train, aes(white, non.white)) +
geom_point(size=2, alpha=0.75) +
geom_point(data=test, size=4, aes(color=test$rf_class)) +
ggtitle('rf_classification') +
